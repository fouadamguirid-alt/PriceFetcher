# ğŸ¤– CryptoBot

## ğŸ“Œ Objectif principal
Construire un **bot de trading crypto automatisÃ©**, capable de collecter des donnÃ©es de marchÃ©, de les traiter en temps rÃ©el, de gÃ©nÃ©rer des signaux basÃ©s sur des modÃ¨les de machine learning et de fournir une interface pour le dÃ©ploiement et le suivi en production.

---

## ğŸ”„ Flux de donnÃ©es (end-to-end)

**ğŸ“¥ Collecte :**  
Appels Ã  lâ€™API Binance pour rÃ©cupÃ©rer en continu les cours et le carnet dâ€™ordres.

**ğŸšš Transport :**  
Messages Kafka pour publier chaque tick de marchÃ©.

**âš™ï¸ Traitement :**  
Jobs Spark (PySpark) qui consomment Kafka, enrichissent/filtrent les donnÃ©es et stockent les rÃ©sultats dans MinIO (data lake).

**ğŸ§  ModÃ©lisation :**  
EntraÃ®nement et infÃ©rence de modÃ¨les (XGBoost, LSTM) sur les donnÃ©es historisÃ©es.

**ğŸŒ API & UI :**  
FastAPI expose les signaux et les mÃ©triques ; Dash fournit un dashboard interactif.

**ğŸ“Œ Orchestration & suivi :**  
Airflow/MLflow pilotent les pipelines ETL, lâ€™entraÃ®nement des modÃ¨les et versionnent les expÃ©riences.

**ğŸš€ DÃ©ploiement :**  
Conteneurisation Docker + dÃ©ploiement Kubernetes pour assurer scalabilitÃ© et haute disponibilitÃ©.

**ğŸ“Š Monitoring :**  
Prometheus collecte les mÃ©triques ; Grafana affiche lâ€™Ã©tat du systÃ¨me et des stratÃ©gies en temps rÃ©el.

---

## ğŸ› ï¸ Principales technologies

| CatÃ©gorie                | Technologies                              |
|--------------------------|-------------------------------------------|
| **Infrastructure**       | Docker, Docker Compose, Kubernetes        |
| **Ingestion & Streaming**| Kafka, Zookeeper                          |
| **Traitement Big Data**  | Spark Streaming (PySpark)                 |
| **Stockage**             | MinIO (S3-compatible)                     |
| **ModÃ©lisation IA**      | XGBoost, LSTM, SHAP (interprÃ©tabilitÃ©)    |
| **APIs & Orchestration** | FastAPI, Airflow, MLflow                  |
| **Visualisation & Monitoring** | Dash, Prometheus, Grafana           |

---

## ğŸš© DÃ©coupage par phases

- âš™ï¸ **Infra de base** : VM Ubuntu + rÃ©seau + Docker Compose
- ğŸ”— **Ingestion** : API Binance + premiers topics Kafka
- ğŸ”„ **Streaming** : Spark â†’ MinIO
- ğŸ“Š **Data Lake** : prÃ©paration des features
- ğŸ¤– **ModÃ©lisation** : entraÃ®nement / infÃ©rence ML
- ğŸš€ **API** : FastAPI pour exposer les signaux
- ğŸ”„ **Orchestration** : Airflow / suivi MLflow
- ğŸ“ˆ **Dashboards** : Prometheus/Grafana
- ğŸ³ **Conteneurisation complÃ¨te**
- â˜¸ï¸ **Production** : Kubernetes

---

## âœ… RÃ©sultat attendu

Un systÃ¨me **modulaire et reproductible** qui :

- Capture et traite les donnÃ©es de marchÃ© en temps rÃ©el.
- GÃ©nÃ¨re des signaux basÃ©s sur une stratÃ©gie hybride (Big Data + ML).
- Assure une orchestration et un monitoring automatisÃ©s pour un dÃ©ploiement fiable en production.
